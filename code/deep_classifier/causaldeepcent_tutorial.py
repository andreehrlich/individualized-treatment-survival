# -*- coding: utf-8 -*-
"""CausalDeepCENT_tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jEtjaxlTLPID2QKTCvMbHJzoojntdTyz

## Install package from GitHub
"""

# !pip3 install git+https://github.com/yicjia/CausalDeepCENT.git -q

from CausalDeepCENT import causal_deepcent as cdc
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import torch
from torch.utils.data import DataLoader, TensorDataset
import lifelines

## check device (CPU or GPU)
if torch.cuda.is_available():
  dev = "cuda:0"
else:
  dev = "cpu"
device = torch.device(dev)

"""## Load data"""

df = pd.read_csv('https://raw.githubusercontent.com/yicjia/CausalDeepCENT/master/METABRIC_4genes.csv')
df["W"] = cdc.getIPW(df["Chemotherapy"],df.drop(["time","event","Chemotherapy"], axis = 1))

## Split the data into training and test sets
train_df, test_df = train_test_split(df, test_size=0.3,random_state=2)

X_train = train_df.drop(["time","event","W"], axis = 1)
NUM_FEATURES = X_train.shape[1]
y_train = np.log(train_df["time"])
E_train = train_df["event"]
W_train = train_df["W"]

X_test = test_df.drop(["time","event","W"], axis = 1)
y_test = np.log(test_df["time"])
E_test = test_df["event"]

scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_train, y_train, E_train, W_train = np.array(X_train), np.array(y_train), np.array(E_train), np.array(W_train)
X_test, y_test, E_test = np.array(X_test), np.array(y_test), np.array(E_test)
train_dataset = TensorDataset(torch.from_numpy(X_train).float().to(device), torch.from_numpy(y_train).float().to(device), torch.from_numpy(E_train).float().to(device), torch.from_numpy(W_train).float().to(device))
test_dataset = TensorDataset(torch.from_numpy(X_test).float().to(device), torch.from_numpy(y_test).float().to(device), torch.from_numpy(E_test).float().to(device))

"""## Run CausalDeepCENT"""

### Define hyperparameters
EPOCHS = 1000
BATCH_SIZE = 512
LEARNING_RATE = 1e-2
NODE = 128
NUM_LAYER = 1
LAMBDA1 = 0.01
DROPOUT = 0.2

y_test_pred, y_test_pred_upper, y_test_pred_lower = cdc.Causal_DeepCENT(train_dataset, test_dataset, NUM_FEATURES, NUM_LAYER, NODE, DROPOUT, LEARNING_RATE, LAMBDA1, EPOCHS, BATCH_SIZE)

# Output the prediction on test set
out_test = pd.DataFrame(list(zip(test_df["time"],np.exp(y_test_pred), np.exp(y_test_pred_lower), np.exp(y_test_pred_upper))),columns=['time','pred_time','pred_time_lower','pred_time_upper'])
# you can then save the dataframe out_test into your Google drive

"""##Get prediction on a new patient"""

## If you have several new patients, please organize them into a dataframe that has the exact same column names as the trainig set in this tutorial,
## and replace the "test_df"

## If you only have one or two new entries, then input the covariates values below
## Here are two individuals with the same covariates value but one without and the other with chemotherapy
Cov = {
 "ER.Status": [0,0],
 "HER2.Status": [0,0],
 "PR.Status": [0,0],
 "Tumor.Size": [25,25],
 "Age.at.Diagnosis.x": [46,46],
 "Lymph.nodes.examined.positive": [8,8],
 "Nottingham.prognostic.index":[6,6],
 "Chemotherapy": [0,1],
 "Hormone.Therapy": [0,0],
 "Inferred.Menopausal.State": [0,0],
 "Radio.Therapy": [1,1],
 "MKI67": [5.96, 5.96],
 "EGFR": [6.19, 6.19],
 "PGR": [11.92, 11.92],
 "ERBB2": [5.27, 5.27]
}

# using the whole dataset as training set
X_train = df.drop(["time","event","W"], axis = 1)
NUM_FEATURES = X_train.shape[1]
y_train = np.log(df["time"])
E_train = df["event"]
W_train = df["W"]

# new entires as test set
X_test_new = pd.DataFrame(Cov)


scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test_new = scaler.transform(X_test_new)
X_train, y_train, E_train, W_train = np.array(X_train), np.array(y_train), np.array(E_train), np.array(W_train)
train_dataset = TensorDataset(torch.from_numpy(X_train).float().to(device), torch.from_numpy(y_train).float().to(device), torch.from_numpy(E_train).float().to(device), torch.from_numpy(W_train).float().to(device))
test_dataset_new = TensorDataset(torch.from_numpy(np.array(X_test_new)).float().to(device), torch.empty(X_test_new.shape[0]), torch.empty(X_test_new.shape[0]))

y_test_pred, y_test_pred_upper, y_test_pred_lower = cdc.Causal_DeepCENT(train_dataset, test_dataset_new, NUM_FEATURES, NUM_LAYER, NODE, DROPOUT, LEARNING_RATE, LAMBDA1, EPOCHS, BATCH_SIZE)

# Output the prediction on test set
out_test = pd.DataFrame(list(zip(np.exp(y_test_pred), np.exp(y_test_pred_lower), np.exp(y_test_pred_upper))),columns=['pred_time','pred_time_lower','pred_time_upper'])
